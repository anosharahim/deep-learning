{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion_recognition.ipynb",
      "provenance": [],
      "mount_file_id": "192k3YMrGdJvp5NHURvd0BHQaxySMxpnl",
      "authorship_tag": "ABX9TyOHlzlPd8VkiFFP1h7sZnlc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anosharahim/deep-learning/blob/master/emotion_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview \n",
        "\n",
        "Transfer Learning using Resnet50 on the FER2013 dataset. \n",
        "\n"
      ],
      "metadata": {
        "id": "z1DDpBNEk70E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRdP8s6JkayQ",
        "outputId": "f860962d-fcab-4842-e08c-7355c9ae81a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import relevant packages and libraries\n"
      ],
      "metadata": {
        "id": "eXXYnPFclXsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for preprocessing\n",
        "import pandas as pd\n",
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "# For plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.io as plt_io\n",
        "import plotly.graph_objects as go\n",
        "%matplotlib inline\n",
        "\n",
        "#machine learning specific \n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as K\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "metadata": {
        "id": "jO5HAZfUkb0H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing "
      ],
      "metadata": {
        "id": "gItCS0cklcJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/Capstone/FER2013/train/'\n",
        "test_path = '/content/drive/MyDrive/Capstone/FER2013/test/'\n",
        "\n",
        "train_data = []\n",
        "train_label = []\n",
        "test_data = []\n",
        "test_label = []\n",
        "\n",
        "num_expressions = 6\n",
        "\n",
        "#keep track of y labels \n",
        "emotion_dictionary = {'angry':0, 'disgusted':1, 'fearful':2, 'happy':3, 'neutral':4, 'sad':5, 'surprised':6}\n",
        "\n",
        "\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]\n",
        "\n",
        "def get_image_arrays(folder_path, label_dict):\n",
        "  data = []\n",
        "  label = []\n",
        "  freq = {}\n",
        "\n",
        "  for category in os.listdir(folder_path): \n",
        "\n",
        "    category_name = label_dict[category]\n",
        "    category_path = folder_path + category + '/'\n",
        "    freq[category] = 0\n",
        "\n",
        "    for image in os.listdir(category_path):\n",
        "      image_file = category_path + image \n",
        "      image_array = imageio.imread(image_file) #get image array from file \n",
        "      #image_array.resize((32, 32))\n",
        "      image_array = np.array(image_array) #convert to numpy array \n",
        "      #add image array and it's label to respective folders \n",
        "      data.append(image_array)\n",
        "      label.append(category_name)\n",
        "      freq[category] += 1\n",
        "\n",
        "  data = np.array(data)\n",
        "  label = np.array(label)\n",
        "\n",
        "  data, label = unison_shuffled_copies(data, label)\n",
        "\n",
        "  return data, label, freq\n",
        "\n",
        "train_data, train_label, train_freq = get_image_arrays(train_path, emotion_dictionary)\n",
        "test_data, test_label, test_freq = get_image_arrays(test_path, emotion_dictionary)"
      ],
      "metadata": {
        "id": "0WugFCD_kg5-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape, train_label.shape)\n",
        "print(test_data.shape, test_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHD9EO-nohis",
        "outputId": "72edce35-8edb-47a3-8e20-7df4368ff237"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28709, 48, 48) (28709,)\n",
            "(7178, 48, 48) (7178,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add 2 more channels to grayscale image to imitate rgb\n",
        "X_train = np.repeat(train_data[..., np.newaxis], 3, -1)\n",
        "x_test = np.repeat(test_data[..., np.newaxis], 3, -1)\n",
        "\n",
        "y_train, y_test = train_label, test_label\n",
        "X_val, X_test, y_val ,y_test = train_test_split(x_test,y_test, test_size=0.3)\n",
        "\n",
        "X_train = np.resize(X_train, (len(X_train), 32, 32,3))\n",
        "X_val = np.resize(X_val, (len(X_val), 32, 32,3))\n",
        "X_test = np.resize(X_test, (len(X_test), 32, 32,3))\n",
        "\n",
        "print('Train -- ', X_train.shape, y_train.shape)\n",
        "print('Val -- ', X_val.shape, y_val.shape)\n",
        "print('Test -- ', X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o2Lhldykqfi",
        "outputId": "67f05377-551d-433d-beda-2816303cd1de"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train --  (28709, 32, 32, 3) (28709,)\n",
            "Val --  (5024, 32, 32, 3) (5024,)\n",
            "Test --  (2154, 32, 32, 3) (2154,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Emotion Class DIstribution in Training Data\")\n",
        "plt.bar(list(train_freq.keys()),list(train_freq.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "jXPXDSVgky3t",
        "outputId": "434c8b7e-eeb3-4397-d78d-c4ccc9d0c79e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 7 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#oversampling minority classes to deal with class imbalance\n",
        "#oversampler = RandomOverSampler(sampling_strategy='minority')\n",
        "#y = train_data.reshape(len(train_data), 48*48)\n",
        "#train_data, train_label = oversampler.fit_resample(T, train_label)\n",
        "\n",
        "#u, c = np.unique(train_label, return_counts=True)\n",
        "#plt.bar(u,c)\n",
        "\n",
        "#Tt = train_data.reshape(len(train_data),48,48)\n"
      ],
      "metadata": {
        "id": "jaYvvP7nk01N"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the ResNet50 Model "
      ],
      "metadata": {
        "id": "78I6b_48lhcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_t = K.Input(shape=(32,32,3))\n",
        "res50_model = K.applications.ResNet50(include_top=False, weights=\"imagenet\",input_tensor=input_t)\n",
        "\n",
        "#freeze the first n layers \n",
        "freeze_layers = 160\n",
        "#only train last 30 layers \n",
        "for layer in res50_model.layers[:freeze_layers]:\n",
        "  layer.trainable =False\n",
        "\n",
        "#verify that the desired layers are frozen \n",
        "for i, layer in enumerate(res50_model.layers):\n",
        "  if i == 10:\n",
        "    print(\"...\")\n",
        "  if i < 10 or i > (freeze_layers - 3):  \n",
        "    print(i,layer.name,'-',layer.trainable)\n",
        "\n",
        "#add further layers \n",
        "model = K.models.Sequential()\n",
        "model.add(res50_model)\n",
        "model.add(K.layers.Dropout(0.2))\n",
        "model.add(K.layers.Flatten())\n",
        "model.add(K.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "'''\n",
        "model.add(res50_model)\n",
        "model.add(K.layers.Dropout(0.5))\n",
        "model.add(K.layers.Flatten())\n",
        "model.add(K.layers.BatchNormalization())\n",
        "model.add(K.layers.Dense(32,kernel_initializer='he_uniform'))\n",
        "model.add(K.layers.BatchNormalization())\n",
        "model.add(K.layers.Activation('relu'))\n",
        "model.add(K.layers.Dropout(0.5))\n",
        "model.add(K.layers.Dense(32,kernel_initializer='he_uniform'))\n",
        "model.add(K.layers.BatchNormalization())\n",
        "model.add(K.layers.Activation('relu'))\n",
        "model.add(K.layers.Dropout(0.5))\n",
        "model.add(K.layers.Dense(32,kernel_initializer='he_uniform'))\n",
        "model.add(K.layers.BatchNormalization())\n",
        "model.add(K.layers.Activation('relu'))\n",
        "model.add(K.layers.Dense(7,activation='softmax'))\n",
        "-----\n",
        "\n",
        "model.add(res50_model)\n",
        "#model.add(K.layers.BatchNormalization())\n",
        "#model.add(K.layers.GlobalAveragePooling2D())\n",
        "model.add(K.layers.Flatten()) \n",
        "model.add(K.layers.Dropout(0.6)) #to avoid overfitting \n",
        "model.add(K.layers.Dense(10, activation='softmax'))\n",
        "'''\n",
        "\n",
        "#Compile the model \n",
        "#since y labels are integers, use sparse categorical cross-entropy \n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer=K.optimizers.Adam(learning_rate=2e-5),#Adam(learning_rate=2e-5),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v43CDQM3k246",
        "outputId": "1d352014-e353-4b1b-fe3c-48754d84230c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_2 - False\n",
            "1 conv1_pad - False\n",
            "2 conv1_conv - False\n",
            "3 conv1_bn - False\n",
            "4 conv1_relu - False\n",
            "5 pool1_pad - False\n",
            "6 pool1_pool - False\n",
            "7 conv2_block1_1_conv - False\n",
            "8 conv2_block1_1_bn - False\n",
            "9 conv2_block1_1_relu - False\n",
            "...\n",
            "158 conv5_block2_2_conv - False\n",
            "159 conv5_block2_2_bn - False\n",
            "160 conv5_block2_2_relu - True\n",
            "161 conv5_block2_3_conv - True\n",
            "162 conv5_block2_3_bn - True\n",
            "163 conv5_block2_add - True\n",
            "164 conv5_block2_out - True\n",
            "165 conv5_block3_1_conv - True\n",
            "166 conv5_block3_1_bn - True\n",
            "167 conv5_block3_1_relu - True\n",
            "168 conv5_block3_2_conv - True\n",
            "169 conv5_block3_2_bn - True\n",
            "170 conv5_block3_2_relu - True\n",
            "171 conv5_block3_3_conv - True\n",
            "172 conv5_block3_3_bn - True\n",
            "173 conv5_block3_add - True\n",
            "174 conv5_block3_out - True\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 1, 1, 2048)        23587712  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1, 1, 2048)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 5,540,874\n",
            "Non-trainable params: 18,067,328\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "bbydWyItlmpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path = os.path.join('/gdrive', 'ckpt', 'fer_2013') \n",
        "\n",
        "#create model checkpoint to save weights\n",
        "check_point = K.callbacks.ModelCheckpoint(filepath=  ckpt_path,\n",
        "                                              monitor=\"val_accuracy\",\n",
        "                                              mode=\"max\",\n",
        "                                              save_best_only=True,)\n",
        "\n",
        "#Train the model \n",
        "history = model.fit(X_train, y_train, batch_size=512,  epochs=5, verbose=1, #batch_size=512,\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        callbacks=[check_point])\n",
        "\n",
        "model.save(ckpt_path) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "YKKC-AmJk4rh",
        "outputId": "afa5253a-8a2a-4129-eff8-1cf9533423fd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "57/57 [==============================] - ETA: 0s - loss: 3.6284 - accuracy: 0.1504"
          ]
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-0553486f5f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m history = model.fit(X_train, y_train, batch_size=512,  epochs=5, verbose=1, #batch_size=512,\n\u001b[1;32m     11\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                         callbacks=[check_point])\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m   \"\"\"\n\u001b[0;32m--> 511\u001b[0;31m   \u001b[0m_pywrap_file_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: /gdrive is not a directory"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results and Interpretation "
      ],
      "metadata": {
        "id": "e8h1LWsmlt4l"
      }
    }
  ]
}