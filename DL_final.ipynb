{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_final",
      "provenance": [],
      "mount_file_id": "https://github.com/anosharahim/deep-learning/blob/master/DL_final.ipynb",
      "authorship_tag": "ABX9TyPOUqaUjx66PNyFXbU2hOJV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anosharahim/deep-learning/blob/master/DL_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages and Libraries"
      ],
      "metadata": {
        "id": "zrSaV5p2_3t4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import math \n",
        "import random \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential, Model \n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, ZeroPadding2D\n",
        "from keras.layers import Dropout, Activation, Flatten, GlobalAveragePooling2D \n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "G6xdo2BhxCnN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "oiq9fqNQ_2Ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load data from gdrive\n",
        "train_npz = np.load(\"/content/drive/MyDrive/Capstone/datasets/train.npz\")\n",
        "test_npz = np.load(\"/content/drive/MyDrive/Capstone/datasets/test.npz\")\n",
        "\n",
        "x_train = train_npz[\"arr_0\"]\n",
        "y_train = train_npz[\"arr_1\"]\n",
        "x_test = test_npz[\"arr_0\"]\n",
        "y_test = test_npz[\"arr_1\"]\n",
        "\n",
        "emotion_dictionary = {'angry':0, 'disgusted':1, 'fearful':2, 'happy':3, 'neutral':4, 'sad':5, 'surprised':6}\n",
        "\n",
        "#randomly undersample majority class \n",
        "class_undersample =  {0: 3995, 1: 436, 2: 4097, 3: 5500, 4: 4965, 5: 4830, 6: 3171}\n",
        "x_train_reshape = x_train.reshape(len(x_train),48*48)\n",
        "undersample = RandomUnderSampler(sampling_strategy=class_undersample)\n",
        "x_train_under, y_train_under = undersample.fit_resample(x_train_reshape,y_train)\n",
        "\n",
        "#oversample minority class  using k-nearest data augmentation\n",
        "class_oversample =  {0: 3995, 1: 3500, 2: 4097, 3: 5500, 4: 4965, 5: 4830, 6: 3171}\n",
        "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "x_train, y_train = sm.fit_resample(x_train_under,y_train_under)\n",
        "\n",
        "#visualize resampled class distribution \n",
        "values, counts_ = np.unique(y_train, return_counts=True)\n",
        "plt.title(\"Emotion Class Distribution in Augmented Training Data\")\n",
        "plt.bar(emotion_dictionary.keys(),counts_, color = 'pink')\n",
        "\n",
        "#add 2 more channels to grayscale image to imitate rgb\n",
        "x_train = np.repeat(x_train[..., np.newaxis], 3, -1)\n",
        "x_test = np.repeat(x_test[..., np.newaxis], 3, -1)\n",
        "\n",
        "#split test set into validation and test set \n",
        "x_val, x_test, y_val ,y_test = train_test_split(x_test,y_test, test_size=0.3)\n",
        "\n",
        "#resize to make sure input is the correct shape\n",
        "x_train = np.resize(x_train, (len(x_train), 48,48,3))\n",
        "x_val = np.resize(x_val, (len(x_val), 48,48,3))\n",
        "x_test = np.resize(x_test, (len(x_test), 48,48,3))\n",
        "\n",
        "print('Train -- ', x_train.shape, y_train.shape)\n",
        "print('Val -- ', x_val.shape, y_val.shape)\n",
        "print('Test -- ', x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "UzbFTyF9xTcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "149efa33-c6b0-4edf-b1d1-872798e219de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train --  (32058, 48, 48, 3) (32058,)\n",
            "Val --  (5024, 48, 48, 3) (5024,)\n",
            "Test --  (2154, 48, 48, 3) (2154,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_datagen(dataset, aug=False):\n",
        "    if aug:\n",
        "        datagen = ImageDataGenerator(\n",
        "                            rescale=1./255,\n",
        "                            featurewise_center=False,\n",
        "                            featurewise_std_normalization=False,\n",
        "                            rotation_range=10,\n",
        "                            width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            zoom_range=0.1,\n",
        "                            horizontal_flip=True)\n",
        "    else:\n",
        "        datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    return datagen.flow_from_directory(\n",
        "            dataset,\n",
        "            target_size=(48, 48),\n",
        "            color_mode='rgb',\n",
        "            shuffle = True,\n",
        "            class_mode='categorical',\n",
        "            batch_size=bs)"
      ],
      "metadata": {
        "id": "7w1_kTspdlBw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "bs = 128\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Capstone/FER2013/train/'\n",
        "val_path = '/content/drive/MyDrive/Capstone/FER2013/val/'\n",
        "test_path = '/content/drive/MyDrive/Capstone/FER2013/test/'\n",
        "\n",
        "train_generator  = get_datagen(train_path, True)\n",
        "val_generator    = get_datagen(val_path)\n",
        "test_generator  = get_datagen(test_path)"
      ],
      "metadata": {
        "id": "4rb7oZQCdnEK",
        "outputId": "bf5a2a5c-5c6e-4b5c-b853-8b2b0256e3ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Found 6069 images belonging to 7 classes.\n",
            "Found 1109 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator"
      ],
      "metadata": {
        "id": "UoWsNJf1ektc",
        "outputId": "de555527-ef1d-4288-8b63-858d83b157e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.preprocessing.image.DirectoryIterator at 0x7f9e5a454690>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Model "
      ],
      "metadata": {
        "id": "MTGxYpJ2_7Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(weights = 'imagenet', include_top=False, input_shape= (48,48,3))\n",
        "n_freeze = 19\n",
        "for layer in vgg.layers[:n_freeze]:\n",
        "  layer.trainable=False\n",
        "\n",
        "for (i,layer) in enumerate(vgg.layers):\n",
        "  print(str(i)+' '+ layer.__class__.__name__, layer.trainable)\n",
        "\n",
        "def fully_connected(base_model, num_classes):\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  x = Dense(num_classes, activation='softmax')(x)\n",
        "  return x\n",
        "\n",
        "num_class = 7\n",
        "FC_head = fully_connected(vgg, num_class)\n",
        "model = Model(inputs=vgg.input, outputs = FC_head)\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWjmwm1n8970",
        "outputId": "4ac91784-1087-43dd-d44c-1966917a46b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 InputLayer False\n",
            "1 Conv2D False\n",
            "2 Conv2D False\n",
            "3 MaxPooling2D False\n",
            "4 Conv2D False\n",
            "5 Conv2D False\n",
            "6 MaxPooling2D False\n",
            "7 Conv2D False\n",
            "8 Conv2D False\n",
            "9 Conv2D False\n",
            "10 MaxPooling2D False\n",
            "11 Conv2D False\n",
            "12 Conv2D False\n",
            "13 Conv2D False\n",
            "14 MaxPooling2D False\n",
            "15 Conv2D False\n",
            "16 Conv2D False\n",
            "17 Conv2D False\n",
            "18 MaxPooling2D False\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 512)              2048      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              525312    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,877,831\n",
            "Trainable params: 3,158,023\n",
            "Non-trainable params: 14,719,808\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training \n",
        "\n",
        "The good thing is that the model is working in a reasonable manner. The bad thing is that the model is overfitting on the training data. What can we do? \n",
        "\n",
        "Training accuracy was about 91% and test/val accuracy was pleatauing at about 42%\n",
        "\n",
        "Added 30% dropout layers where overfitting decreases but performance still plateaued at about ~40 for validation set\n",
        "\n",
        "- Added Dropout \n",
        "- Used global average pooling: layer helps aggregate feature map information and helps prevent overfitting caused by fully connected layers in the\n",
        "model\n",
        "- Tried all three different optimizers \n",
        "- Data augmentation --- but Image data generator eta is in 4 hours and more\n",
        "- Tried using balanced vs imbalanced training data but no change  \n",
        "- Try using unfrozen layers [but when i do this loss becomes NaN]\n",
        "- Tried adding batch norm 2% improvement\n"
      ],
      "metadata": {
        "id": "63932i95_-o5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "rms_lr = 0.001\n",
        "sgd_lr = 0.01\n",
        "adam_lr = 0.001\n",
        "sgd_decay = 0.0001\n",
        "\n",
        "sgd = SGD(learning_rate=sgd_lr, momentum=0.9, decay=sgd_decay, nesterov=True) \n",
        "adam = Adam(learning_rate=adam_lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "rms = RMSprop(learning_rate=rms_lr)\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
        "\n",
        "lrd = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=0.00001, verbose=1)\n",
        "es = EarlyStopping(monitor = 'val_accuracy', min_delta = 0, patience = 10, verbose = 1, restore_best_weights = True)\n",
        "checkpoint = ModelCheckpoint('face_vgg.h5', monitor = 'val_accuracy', mode ='max', save_best_only = True, verbose=1)\n",
        "callbacks = [checkpoint, es, lrd]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(train_generator, #x_train, y_train,  \n",
        "                    epochs=epochs, \n",
        "                    verbose=1,\n",
        "                    validation_data= val_generator, #(x_val, y_val),\n",
        "                    max_queue_size=100,\n",
        "                    workers = 10 ,# (set a proper value > 1)\n",
        "                    use_multiprocessing=True,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-fFpOXa8_zB",
        "outputId": "fb3bb6ae-4514-40df-f555-5d436901b625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "225/225 [==============================] - ETA: 0s - loss: 1.4783 - accuracy: 0.4292\n",
            "Epoch 1: val_accuracy improved from -inf to 0.44818, saving model to face_vgg.h5\n",
            "225/225 [==============================] - 119s 504ms/step - loss: 1.4783 - accuracy: 0.4292 - val_loss: 1.4513 - val_accuracy: 0.4482 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "225/225 [==============================] - ETA: 0s - loss: 1.4778 - accuracy: 0.4262\n",
            "Epoch 2: val_accuracy did not improve from 0.44818\n",
            "225/225 [==============================] - 94s 402ms/step - loss: 1.4778 - accuracy: 0.4262 - val_loss: 1.4786 - val_accuracy: 0.4406 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "225/225 [==============================] - ETA: 0s - loss: 1.4786 - accuracy: 0.4245\n",
            "Epoch 3: val_accuracy improved from 0.44818 to 0.45131, saving model to face_vgg.h5\n",
            "225/225 [==============================] - 112s 484ms/step - loss: 1.4786 - accuracy: 0.4245 - val_loss: 1.4350 - val_accuracy: 0.4513 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "225/225 [==============================] - ETA: 0s - loss: 1.4726 - accuracy: 0.4335\n",
            "Epoch 4: val_accuracy did not improve from 0.45131\n",
            "225/225 [==============================] - 111s 479ms/step - loss: 1.4726 - accuracy: 0.4335 - val_loss: 1.4540 - val_accuracy: 0.4487 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "225/225 [==============================] - ETA: 0s - loss: 1.4678 - accuracy: 0.4325\n",
            "Epoch 5: val_accuracy did not improve from 0.45131\n",
            "225/225 [==============================] - 111s 482ms/step - loss: 1.4678 - accuracy: 0.4325 - val_loss: 1.4453 - val_accuracy: 0.4500 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "225/225 [==============================] - ETA: 0s - loss: 1.4545 - accuracy: 0.4381\n",
            "Epoch 6: val_accuracy did not improve from 0.45131\n",
            "225/225 [==============================] - 92s 397ms/step - loss: 1.4545 - accuracy: 0.4381 - val_loss: 1.4453 - val_accuracy: 0.4495 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "225/225 [==============================] - ETA: 0s - loss: 1.4600 - accuracy: 0.4338\n",
            "Epoch 7: val_accuracy did not improve from 0.45131\n",
            "225/225 [==============================] - 93s 399ms/step - loss: 1.4600 - accuracy: 0.4338 - val_loss: 1.4394 - val_accuracy: 0.4510 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "225/225 [==============================] - ETA: 0s - loss: 1.4507 - accuracy: 0.4400\n",
            "Epoch 8: val_accuracy improved from 0.45131 to 0.45428, saving model to face_vgg.h5\n",
            "225/225 [==============================] - 125s 529ms/step - loss: 1.4507 - accuracy: 0.4400 - val_loss: 1.4378 - val_accuracy: 0.4543 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "225/225 [==============================] - ETA: 0s - loss: 1.4382 - accuracy: 0.4453\n",
            "Epoch 9: val_accuracy did not improve from 0.45428\n",
            "225/225 [==============================] - 93s 400ms/step - loss: 1.4382 - accuracy: 0.4453 - val_loss: 1.4426 - val_accuracy: 0.4521 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "225/225 [==============================] - ETA: 0s - loss: 1.4394 - accuracy: 0.4448\n",
            "Epoch 10: val_accuracy did not improve from 0.45428\n",
            "225/225 [==============================] - 105s 440ms/step - loss: 1.4394 - accuracy: 0.4448 - val_loss: 1.4490 - val_accuracy: 0.4539 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "225/225 [==============================] - ETA: 0s - loss: 1.4415 - accuracy: 0.4413\n",
            "Epoch 11: val_accuracy improved from 0.45428 to 0.45691, saving model to face_vgg.h5\n",
            "225/225 [==============================] - 112s 484ms/step - loss: 1.4415 - accuracy: 0.4413 - val_loss: 1.4349 - val_accuracy: 0.4569 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "225/225 [==============================] - ETA: 0s - loss: 1.4291 - accuracy: 0.4448\n",
            "Epoch 12: val_accuracy did not improve from 0.45691\n",
            "225/225 [==============================] - 94s 401ms/step - loss: 1.4291 - accuracy: 0.4448 - val_loss: 1.4389 - val_accuracy: 0.4548 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "225/225 [==============================] - ETA: 0s - loss: 1.4360 - accuracy: 0.4465\n",
            "Epoch 13: val_accuracy did not improve from 0.45691\n",
            "225/225 [==============================] - 104s 435ms/step - loss: 1.4360 - accuracy: 0.4465 - val_loss: 1.4325 - val_accuracy: 0.4546 - lr: 0.0100\n",
            "Epoch 14/100\n",
            " 60/225 [=======>......................] - ETA: 1:12 - loss: 1.4166 - accuracy: 0.4517"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process Keras_worker_ForkPoolWorker-1471:\n",
            "Traceback (most recent call last):\n",
            "Process Keras_worker_ForkPoolWorker-1478:\n",
            "Process Keras_worker_ForkPoolWorker-1476:\n",
            "Process Keras_worker_ForkPoolWorker-1473:\n",
            "Process Keras_worker_ForkPoolWorker-1475:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "Process Keras_worker_ForkPoolWorker-1472:\n",
            "Process Keras_worker_ForkPoolWorker-1474:\n",
            "Process Keras_worker_ForkPoolWorker-1479:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Process Keras_worker_ForkPoolWorker-1480:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n",
            "    interpolation=self.interpolation)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n",
            "    interpolation=self.interpolation)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n",
            "    interpolation=self.interpolation)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n",
            "    img = pil_image.open(io.BytesIO(f.read()))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 113, in load_img\n",
            "    with open(path, 'rb') as f:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n",
            "    interpolation=self.interpolation)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n",
            "    interpolation=self.interpolation)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n",
            "    img = pil_image.open(io.BytesIO(f.read()))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 113, in load_img\n",
            "    with open(path, 'rb') as f:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n",
            "    interpolation=self.interpolation)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
            "    return self._get_batches_of_transformed_samples(index_array)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n",
            "    interpolation=self.interpolation)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n",
            "    interpolation=self.interpolation)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 113, in load_img\n",
            "    with open(path, 'rb') as f:\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 113, in load_img\n",
            "    with open(path, 'rb') as f:\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n",
            "    interpolation=self.interpolation)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 113, in load_img\n",
            "    with open(path, 'rb') as f:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 113, in load_img\n",
            "    with open(path, 'rb') as f:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 113, in load_img\n",
            "    with open(path, 'rb') as f:\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "Process Keras_worker_ForkPoolWorker-1488:\n",
            "Process Keras_worker_ForkPoolWorker-1477:\n",
            "Process Keras_worker_ForkPoolWorker-1486:\n",
            "Process Keras_worker_ForkPoolWorker-1483:\n",
            "Process Keras_worker_ForkPoolWorker-1487:\n",
            "Process Keras_worker_ForkPoolWorker-1484:\n",
            "Process Keras_worker_ForkPoolWorker-1481:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Process Keras_worker_ForkPoolWorker-1485:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Process Keras_worker_ForkPoolWorker-1489:\n",
            "Process Keras_worker_ForkPoolWorker-1482:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
            "    with self._rlock:\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_generator, verbose=1)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8tv4YHkAUrh",
        "outputId": "bcb7ff42-22d3-45df-f0dd-69eae1597933"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 231s 29s/step - loss: 1.4694 - accuracy: 0.4112\n",
            "Restored model, accuracy: 41.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, unfortunately, augmentation is doing in CPU if you using ImageDataGenerator, and CPU is not \"parallel\" enough to process matrix multiply. Each time you doing augmentation, is very time consuming. Try reduce your transformation type, or doing it with opencv under GPU version. Hope it help.\n",
        "\n",
        "\n",
        "Make a long story ---- \n",
        "show insight about everything you tried in a strategic manner. //\n",
        "Reading literature -- talk about SOTA //\n",
        "give a strong story -- //\n",
        "this is why it is an extension \n",
        "smaller network and why this is valuable \n",
        "talk about costs etc...\n",
        "Two types of engineer -- what is the most amazing vs what is the cheapest engineer //// \n",
        "we are looking for arch with small no. of trainable parameters \n",
        "easier to train with smaller dataset\n",
        "\n",
        "\n",
        "## Questions\n",
        "\n",
        "- Why is validation accuracy greater than training accuracy after adding dropout? \n",
        "- Why does my val loss doesn't decrease but val accuracy increases?\n",
        "\n",
        "## Notes\n",
        "\n",
        "**Momentum**\n",
        "\n",
        "momentum: that accelerates gradient descent in the relevant direction and dampens oscillations Momentum speeds up movement along directions of strong improvement (loss decrease) and also helps the network avoid local minima.\n",
        "\n",
        "**Nesterov momentum**\n",
        "\n",
        "nesterov momentum is a simple change to normal momentum. Here the gradient term is not computed from the current position\n",
        "while gradient may point in right direction, momentum may not always, so the intermediate position is found to redirect momentum \n",
        "\n",
        "## References \n",
        "\n",
        "1. https://dominikschmidt.xyz/nesterov-momentum/\n",
        "2. https://medium.com/@heba.elshatoury/predicting-emotion-from-facial-expression-88acc43f96f5"
      ],
      "metadata": {
        "id": "EooDMtsmBvNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sFQSLEaYCA20"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}